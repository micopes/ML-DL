최윤호 교수님 
10/7 (수) 수업

Block Chain 코드 보안 -> 코드 분석이 크게 필요하지 않게 딥러닝 적용

Adversarial (적대적 공격)

사람의 눈에는 정상적으로 보이지만
실제로는 제대로 동작하지 않는 딥러닝에서의 오류를 유발하는 공격.

ex) 아이유 + 노이즈 -> 신봉선.

실제로는 심각한 것을 유발할 수 있음.
ex) 자율주행 표지판.

1. 공격기법의 종류
2. 이러한 공격을 어떻게 방해할 수 있는가?
3. 고도화. 사람의 눈에는 어떻게 더 적절하게 보이게 만드는가?
4. 자연어 처리 등의 다른 분야에서도 적용가능하게 만드는 것.
